{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryan/github/generative-ai/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "from huggingface_hub import login\n",
    "from transformers import HfAgent\n",
    "\n",
    "from langchain.chat_models import Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "HUGGINGFACE_ACCESS_TOKEN=getpass(\"Enter Your HuggingFace API Access Token:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/ryan/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(HUGGINGFACE_ACCESS_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starcoder\n",
    "# agent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoder\")\n",
    "# StarcoderBase\n",
    "agent = HfAgent(\"https://api-inference.huggingface.co/models/bigcode/starcoderbase\")\n",
    "# OpenAssistant\n",
    "# agent = HfAgent(url_endpoint=\"https://api-inference.huggingface.co/models/OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error 503: {'error': 'Model bigcode/starcoderbase is currently loading', 'estimated_time': 2531.111572265625}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mSummarize the content from the following website - https://huggingface.co/docs/transformers/transformers_agents\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/github/generative-ai/venv/lib/python3.10/site-packages/transformers/tools/agents.py:335\u001b[0m, in \u001b[0;36mAgent.run\u001b[0;34m(self, task, return_code, remote, **kwargs)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39mSends a request to the agent.\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[39m```\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    334\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mformat_prompt(task)\n\u001b[0;32m--> 335\u001b[0m result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_one(prompt, stop\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mTask:\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m    336\u001b[0m explanation, code \u001b[39m=\u001b[39m clean_code_for_run(result)\n\u001b[1;32m    338\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlog(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m==Explanation from the agent==\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00mexplanation\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/github/generative-ai/venv/lib/python3.10/site-packages/transformers/tools/agents.py:643\u001b[0m, in \u001b[0;36mHfAgent.generate_one\u001b[0;34m(self, prompt, stop)\u001b[0m\n\u001b[1;32m    641\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate_one(prompt)\n\u001b[1;32m    642\u001b[0m \u001b[39melif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m--> 643\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mError \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mjson()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    645\u001b[0m result \u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mjson()[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mgenerated_text\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    646\u001b[0m \u001b[39m# Inference API returns the stop sequence\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Error 503: {'error': 'Model bigcode/starcoderbase is currently loading', 'estimated_time': 2531.111572265625}"
     ]
    }
   ],
   "source": [
    "res = agent.run(\"Summarize the content from the following website - https://huggingface.co/docs/transformers/transformers_agents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Transformers is a training tool for TensorFlow. It allows you to create and train models. It's free and available to download and use. It has a lot of documentation. It also has some training tools. It can be used to improve performance and scalability.\""
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
