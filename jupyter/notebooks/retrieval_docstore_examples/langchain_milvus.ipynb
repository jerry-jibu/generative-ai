{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ENSURE THAT THE ETCD, MINIO, AND MILVUS SERVICES IN docker-compose.yml\n",
    "### ARE UNCOMMENTED AND RUNNING IF YOU WANT TO USE THE CONTAINERIZED INSTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Milvus\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "from textwrap import dedent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MILVUS_HOST = \"localhost\" # When running notebook outside of compoose jupyter container\n",
    "MILVUS_HOST = \"milvus\" # When running notebook inside of compose jupyter container\n",
    "MILVUS_PORT = 19530\n",
    "# MILVUS_HTTPS_URL= f\"https://{MILVUS_HOST}:{MILVUS_PORT}\"\n",
    "MILVUS_USER = \"root\"\n",
    "MILVUS_PASSWORD = \"milvus\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model_name = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name=embeddings_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loader = TextLoader(\"../../../data/state_of_the_union.txt\")\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=75)\n",
    "docs = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Milvus.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    connection_args={\"host\":MILVUS_HOST, \"port\":MILVUS_PORT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How much does the president want to cut the cancer death rate?\"\n",
    "docs = docsearch.similarity_search(query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTANT NOTE If you want to use the Mistral 7B Model\n",
    "## As of 10/7/2023, need to run the pip install below, as Mistral is not included in main transformers library yet\n",
    "# !pip install git+https://github.com/huggingface/transformers.git\n",
    "\n",
    "## RESTART THE KERNEL AFTER INSTALLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = \"PY007/TinyLlama-1.1B-Chat-v0.3\"\n",
    "# model_name = \"TheBloke/CollectiveCognition-v1.1-Mistral-7B-GPTQ\"\n",
    "model_name = \"TheBloke/Llama-2-13B-chat-GPTQ\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, \n",
    "                                             device_map=\"auto\",\n",
    "                                             )\n",
    "# model=model.to(\"cuda\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name,\n",
    "                                          device_map=\"auto\"\n",
    "                                          )\n",
    "pipe = pipeline(task=\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Model without any additional context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"How much does the president want to cut the cancer death rate?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer.encode(query, return_tensors=\"pt\").to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/transformers/generation/utils.py:1411: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_tensor = model.generate(inputs, min_new_tokens=25, max_new_tokens=100, repetition_penalty=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    1,  1128,  1568,   947,   278,  6673,   864,   304,  5700,   278,\n",
       "        23900,  4892,  6554, 29973,    13,  1576,  7178, 30010, 29879,  7038,\n",
       "          657,   363,   383,   275,  1052,  8905, 29871, 29906, 29900, 29896,\n",
       "        29947,  7805,   263,  2009,   310,   395, 29946, 29889, 29955, 24464,\n",
       "          363,   278,  3086,  1815,  2265,  8907,   313, 29940,  8426,   511,\n",
       "          607,   338,   385,  7910,   310,   395, 29941, 29945, 29953,  7284,\n",
       "          975,   278,  1857,  3233, 29889,   910, 11524,   263, 29871, 29929,\n",
       "        10151,  7910,  2038,   278, 16436,  1052,  1629, 29871, 29906, 29900,\n",
       "        29896, 29955,  7128,   362, 29892,   322,   723,  6963,  3001,   405,\n",
       "        29902, 29950,  5220,   292,   304,   395, 29941, 29896, 29889, 29947,\n",
       "        24464, 29889,   450, 23562,   884,  9551,   267,   304, 10127,   263,\n",
       "          716,  1346,  6028,  2265], device='cuda:0')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the token ID's for the generated response\n",
    "output_tensor[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We decode the tokens like this (instead of decoding the entire output_tensor)\n",
    "## so that we don't include the propmt itself in the output\n",
    "generated_text = tokenizer.batch_decode(output_tensor[:, inputs.shape[1]:])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The President’s Budget for Fiscal Year 2018 includes a request of $4.7 billion for the National Cancer Institute (NCI), which is an increase of $356 million over the current level. This represents a 9 percent increase above the fiscal year 2017 appropriation, and would bring total NIH funding to $31.8 billion. The budget also proposes to establish a new “Cancer\n"
     ]
    }
   ],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the model with retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_retrieval_qa(query, k=4, min_new_tokens=1, max_new_tokens=20, return_sources=True, repetition_penalty=1.0, remove_tokens=(\"<s>\",\"</s>\")):\n",
    "    docs = docsearch.similarity_search(query, k=k)\n",
    "\n",
    "    context = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "    template = PromptTemplate(template=dedent(f\"\"\"\"\n",
    "    <SYS>You are a question-and-answer assistant that only uses information from the provided context when responding.</SYS>\n",
    "    \n",
    "    <s>[INST] Use the context to answer the question. Be detailed and specific in your answers, but do not include anything besides the answer to the question in your response.\n",
    "    \n",
    "    Context: {context}\n",
    "\n",
    "    Question: {{query}}[/INST]\n",
    "\n",
    "    Answer: \n",
    "    \"\"\"), input_variables=[\"query\"])\n",
    "\n",
    "    prompt = template.format(query=query)\n",
    "\n",
    "    input_tensor = tokenizer.encode(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_tensor = model.generate(input_tensor, min_new_tokens=min_new_tokens, max_new_tokens=max_new_tokens, repetition_penalty=repetition_penalty)\n",
    "\n",
    "    generated_tensor = output_tensor[:, input_tensor.shape[1]:]\n",
    "\n",
    "    ## The batch_decode call below removes the input tokens\n",
    "    generated_text = tokenizer.batch_decode(generated_tensor)[0]\n",
    "    \n",
    "    for token in remove_tokens:\n",
    "        generated_text = generated_text.replace(token,\"\")\n",
    "    generated_text = generated_text.strip('\" \\n')\n",
    "    \n",
    "    output = {\n",
    "        \"text\": generated_text,\n",
    "        \"output_token_length\":len(generated_tensor[0])\n",
    "    }\n",
    "    if return_sources: output[\"sources\"] = docs\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = run_retrieval_qa(query, min_new_tokens=150, max_new_tokens=300, repetition_penalty=1.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'The President wants to cut the cancer death rate by at least 50% over the next 25 years. This is part of the Cancer Moonshot initiative that was launched six years ago by President Obama, and the goal is to turn more cancers from death sentences into treatable diseases, with more support for patients and families. To achieve this ambitious goal, the President is calling on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health. The focus is on making significant progress in the fight against cancer, which is currently the second leading cause of death in America, after heart disease. The aim is to save countless lives and improve the quality of life for those affected by cancer.',\n",
       " 'output_token_length': 154,\n",
       " 'sources': [Document(page_content='Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.', metadata={'source': '../../data/state_of_the_union.txt'}),\n",
       "  Document(page_content='Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.', metadata={'source': '../../data/state_of_the_union.txt'}),\n",
       "  Document(page_content='Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.', metadata={'source': '../../../data/state_of_the_union.txt'}),\n",
       "  Document(page_content='Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.', metadata={'source': '../../data/state_of_the_union.txt'})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing Multiple Vector Fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a \"summary\" field for the documents we want to index, so we will have both a \"page_content\" field and a \"summary\" field to embed and store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "milvus_docs = [doc.dict() for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text:str, min_new_tokens=1, max_new_tokens=200, repetition_penalty=1.1):\n",
    "    \n",
    "    summarization_template_string = \"\"\"[SYS]You are an assistant with a great ability for summarizing text content.[/SYS]\n",
    "    \n",
    "    <s>[INST]Summarize the following information. Capture the important information, but be as concise as possible.\n",
    "\n",
    "    Information: {document}[/INST]\n",
    "\n",
    "    Summary: \"\"\"\n",
    "    summarization_template = PromptTemplate(template=summarization_template_string, input_variables=[\"document\"])\n",
    "    \n",
    "    summarization_prompt = summarization_template.format(document=text)\n",
    "\n",
    "    input_tensor = tokenizer.encode(summarization_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output_tensor = model.generate(\n",
    "                                   input_tensor, \n",
    "                                   min_new_tokens=min_new_tokens, \n",
    "                                   max_new_tokens=max_new_tokens, \n",
    "                                   repetition_penalty=repetition_penalty\n",
    "                                  )\n",
    "\n",
    "    generated_text = tokenizer.batch_decode(output_tensor[:, input_tensor.shape[1]:])[0]\n",
    "    \n",
    "\n",
    "    try:\n",
    "        generated_text = generated_text.split(\"Summary: \")[1]\n",
    "    except IndexError:\n",
    "        pass\n",
    "    \n",
    "\n",
    "    replace_tokens = (\"<s>\",\"</s>\")\n",
    "    for token in replace_tokens:\n",
    "        generated_text = generated_text.replace(token,\"\")\n",
    "    generated_text = generated_text.strip()\n",
    "    \n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, doc in enumerate(milvus_docs):\n",
    "    doc[\"id\"] = i+1\n",
    "    text = doc[\"page_content\"]\n",
    "    summary = summarize_text(text)\n",
    "    doc[\"summary\"] = summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Milvus DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, db, MilvusException, utility\n",
    "\n",
    "conn = connections.connect(host=MILVUS_HOST, port=MILVUS_PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RPC error: [create_database], <MilvusException: (code=1, message=database already exist: mydb)>, <Time:{'RPC start': '2023-10-15 16:01:29.626586', 'RPC error': '2023-10-15 16:01:29.628562'}>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database mydb already exists. Skipping creation...\n"
     ]
    }
   ],
   "source": [
    "db_name = \"mydb\"\n",
    "try:\n",
    "    database = db.create_database(db_name)\n",
    "except MilvusException as e:\n",
    "    if e.code == 1:\n",
    "        print(f\"Database {db_name} already exists. Skipping creation...\")\n",
    "        db.using_database(db_name)\n",
    "    else:\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['default', 'mydb']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.list_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Schema and Collection using the Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import CollectionSchema, FieldSchema, DataType, Collection\n",
    "doc_id = FieldSchema(\n",
    "  name=\"id\",\n",
    "  dtype=DataType.INT64,\n",
    "  is_primary=True,\n",
    ")\n",
    "page_content = FieldSchema(\n",
    "  name=\"page_content\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=1000,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"NONE\"\n",
    ")\n",
    "page_content_vector = FieldSchema(\n",
    "  name=\"page_content_vector\",\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=embeddings.client.get_sentence_embedding_dimension()\n",
    ")\n",
    "summary = FieldSchema(\n",
    "  name=\"summary\",\n",
    "  dtype=DataType.VARCHAR,\n",
    "  max_length=1000,\n",
    "  # The default value will be used if this field is left empty during data inserts or upserts.\n",
    "  # The data type of `default_value` must be the same as that specified in `dtype`.\n",
    "  default_value=\"NONE\"\n",
    ")\n",
    "summary_vector = FieldSchema(\n",
    "  name=\"summary_vector\",\n",
    "  dtype=DataType.FLOAT_VECTOR,\n",
    "  dim=embeddings.client.get_sentence_embedding_dimension()\n",
    ")\n",
    "metadata = FieldSchema(\n",
    "    name=\"metadata\",\n",
    "    dtype=DataType.JSON\n",
    ")\n",
    "\n",
    "## HAVE TO CREATE MULTIPLE COLLECTIONS BECAUSE MILVUS MULTI-VECTOR NOT SUPPORTED YET (as of 10/12/2023)\n",
    "page_content_schema = CollectionSchema(\n",
    "  fields=[doc_id, page_content, page_content_vector, summary, metadata],\n",
    "  description=\"SOTU Search with page content vector\",\n",
    "  enable_dynamic_field=True\n",
    ")\n",
    "summary_schema = CollectionSchema(\n",
    "  fields=[doc_id, page_content, summary, summary_vector, metadata],\n",
    "  description=\"SOTU Search with summary vector\",\n",
    "  enable_dynamic_field=True\n",
    ")\n",
    "page_content_collection_name = \"sotu_text\"\n",
    "summary_collection_name = \"sotu_summary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "DROP_COLLECTION_IF_EXISTS=True\n",
    "if DROP_COLLECTION_IF_EXISTS:\n",
    "    for collection_name in [page_content_collection_name, summary_collection_name]:\n",
    "        utility.drop_collection(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content_collection = Collection(\n",
    "    name=page_content_collection_name,\n",
    "    schema=page_content_schema,\n",
    "    using='default',\n",
    "    shards_num=1\n",
    ")\n",
    "summary_collection = Collection(\n",
    "    name=summary_collection_name,\n",
    "    schema=summary_schema,\n",
    "    using='default',\n",
    "    shards_num=1\n",
    ")\n",
    "\n",
    "## TO GET EXISTING COLLECTIONS\n",
    "# page_content_collection = Collection(page_content_collection_name)\n",
    "# summary_collection = Collection(summary_collection_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create embeddings for the \"page_content\" and \"summary\" fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(text:str, embedding_model=embeddings):\n",
    "    return embedding_model.embed_documents(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in milvus_docs:\n",
    "    for field in [\"page_content\", \"summary\"]:\n",
    "        doc[f\"{field}_vector\"] = generate_embeddings(doc[field])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Documents to Milvus Collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 10, delete count: 10, upsert count: 10, timestamp: 444959474457772035, success count: 10, err count: 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_content_collection.upsert(milvus_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(insert count: 10, delete count: 10, upsert count: 10, timestamp: 444959474457772044, success count: 10, err count: 0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_collection.upsert(milvus_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Index Vectors in Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_params = {\n",
    "  \"metric_type\":\"L2\",\n",
    "  \"index_type\":\"IVF_FLAT\",\n",
    "  \"params\":{\"nlist\":1024}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(code=0, message=)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_content_collection.create_index(\n",
    "  field_name=\"page_content_vector\", \n",
    "  index_params=index_params\n",
    ")\n",
    "\n",
    "summary_collection.create_index(\n",
    "  field_name=\"summary_vector\", \n",
    "  index_params=index_params\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'total_rows': 0, 'indexed_rows': 0, 'pending_index_rows': 0}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility.index_building_progress(\"sotu_text\")\n",
    "# Output: {'total_rows': 0, 'indexed_rows': 0}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content_collection.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_params = {\n",
    "    \"metric_type\": \"L2\", \n",
    "    # \"offset\": 5, \n",
    "    \"ignore_growing\": False, \n",
    "    \"params\": {\"nprobe\": 10}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_vector = embeddings.embed_documents(\"Cancer Moonshot initiative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = page_content_collection.search(\n",
    "    data=search_vector, \n",
    "    anns_field=\"page_content_vector\", \n",
    "    # the sum of `offset` in `param` and `limit` \n",
    "    # should be less than 16384.\n",
    "    param=search_params,\n",
    "    limit=2,\n",
    "    expr=None,\n",
    "    # set the names of the fields you want to \n",
    "    # retrieve from the search result.\n",
    "    output_fields=['page_content'],\n",
    "    consistency_level=\"Strong\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id: 2, distance: 2.0121756908256239e-13, entity: {'page_content': 'Cancer is the #2 cause of death in America–second only to heart disease. \\n\\nLast month, I announced our plan to supercharge  \\nthe Cancer Moonshot that President Obama asked me to lead six years ago. \\n\\nOur goal is to cut the cancer death rate by at least 50% over the next 25 years, turn more cancers from death sentences into treatable diseases.  \\n\\nMore support for patients and families. \\n\\nTo get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BELOW STILL IN PROGRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval with Reranking (Boosting with Text Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
