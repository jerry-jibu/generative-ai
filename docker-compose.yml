version: '3.9'

services:
  jupyter:
    build: ./jupyter
    ports: 
      - 8888:8888
    volumes:
      - ./data:/workspace/data
      - ./jupyter/notebooks/:/workspace/notebooks/
      - ./.env:/workspace/.env
      - ~/.cache/:/root/.cache/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
  chroma:
    image: chromadb/chroma
    command: uvicorn chromadb.app:app --reload --workers 1 --host 0.0.0.0 --port 8000 --log-config chromadb/log_config.yml
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=${PERSIST_DIRECTORY:-/chroma/chroma}
      - ANONYMIZED_TELEMETRY=False
      # - CHROMA_SERVER_AUTH_PROVIDER=${CHROMA_SERVER_AUTH_PROVIDER}
      # - CHROMA_SERVER_AUTH_CREDENTIALS_FILE=${CHROMA_SERVER_AUTH_CREDENTIALS_FILE}
      # - CHROMA_SERVER_AUTH_CREDENTIALS=${CHROMA_SERVER_AUTH_CREDENTIALS}
      # - CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER=${CHROMA_SERVER_AUTH_CREDENTIALS_PROVIDER}
      # - CHROMA_OTEL_EXPORTER_ENDPOINT=${CHROMA_OTEL_EXPORTER_ENDPOINT}
      # - CHROMA_OTEL_EXPORTER_HEADERS=${CHROMA_OTEL_EXPORTER_HEADERS}
      # - CHROMA_OTEL_SERVICE_NAME=${CHROMA_OTEL_SERVICE_NAME}
      # - CHROMA_OTEL_GRANULARITY=${CHROMA_OTEL_GRANULARITY}
    ports:
      - 8000:8000
    volumes:
      - chroma-data:/chroma
    healthcheck:
      test: ["CMD","curl", "http://localhost:8000/api/v1/heartbeat", "-H", "'accept: application/json'"]
      interval: 1m30s
      timeout: 30s
      retries: 5
      start_period: 30s
  
  streamlit:
    build: ./streamlit_app/
    environment:
      - CHROMADB_HOST=chroma
      - CHROMADB_PORT=8000
    ports:
      - 8501:8501
    volumes:
      - ./streamlit_app/:/app/
      - ~/.cache/:/root/.cache/
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  
  text-generation-inference:
    image: ghcr.io/huggingface/text-generation-inference
    ports:
      - 3000:3000
    command: ["--model-id", "TheBloke/Mistral-7B-Instruct-v0.2-GPTQ", "--revision", "gptq-8bit-128g-actorder_True", "--port", "3000", "--quantize", "gptq", "--max-input-length", "3696", "--max-total-tokens", "4096", "--max-batch-prefill-tokens", "4096"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - tgi-data:/data

volumes:
  chroma-data:
  tgi-data: